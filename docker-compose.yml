services:
  mongo:
    image: mongo:latest
    container_name: "laia_mongo"
    logging:
      options:
        max-size: 1g
    environment:
      MONGO_INITDB_ROOT_USERNAME: "laia"
      MONGO_INITDB_ROOT_PASSWORD: "laia"
    ports:
      - 27017:27017
    volumes:
      - mongo_data:/data/db
    networks:
      - local
    restart: always
  
  qdrant:
    image: qdrant/qdrant:latest
    container_name: "laia_qdrant"
    ports:
      - 6333:6333
      - 6334:6334
    expose:
      - 6333
      - 6334
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - local
    restart: always



  postgres:
    image: postgres:14
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - local
    restart: always
    

  airflow:
    image: apache/airflow:2.9.0-python3.11
    container_name: airflow_webserver
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__RBAC: "true"
      AIRFLOW__WEBSERVER__SECRET_KEY: "temporary_secret_key"
      AIRFLOW__CORE__FERNET_KEY: "temporary_fernet_key"
      _AIRFLOW_WWW_USER_USERNAME: airflow
      _AIRFLOW_WWW_USER_PASSWORD: airflow
    ports:
      - "8080:8080"
    volumes:
      - ./backend/etl/dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: bash -c "airflow db migrate && airflow users create --username airflow --firstname Airflow --lastname Admin --role Admin --email admin@example.com --password airflow && airflow scheduler & airflow webserver"
    networks:
      - local
    restart: always
    

volumes:
  mongo_data:
  postgres_data:
  qdrant_data:


networks:
  local:
    driver: bridge

